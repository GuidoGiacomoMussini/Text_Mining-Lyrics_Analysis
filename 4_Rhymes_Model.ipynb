{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNt3Z4udyFf7gTbFVlIh/DH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuidoGiacomoMussini/Text_Mining-Lyrics_Analysis/blob/main/4_Rhymes_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "LZWpeOy-zSnE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4gpN4hFzMXR",
        "outputId": "c122590d-c15e-414d-f3d9-86a4033d8095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import re\n",
        "import string\n",
        "import itertools\n",
        "import pickle\n",
        "import random\n",
        "from tqdm import tqdm as progress_bar\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the file with the rhymes\n",
        "files_path = '/content/drive/MyDrive/Colab Notebooks/Text Mining/Files/'\n",
        "with open(files_path+'rhymes_list.pickle', 'rb') as f:\n",
        "    rhymes = pickle.load(f)\n",
        "with open(files_path+'rhymes_idx.pickle', 'rb') as f:\n",
        "    idx = pickle.load(f)"
      ],
      "metadata": {
        "id": "cxDzbyGckUEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the dataset"
      ],
      "metadata": {
        "id": "nTKxC3uWBR__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# aggregates all the words that rhyme\n",
        "df_grp = pd.DataFrame()\n",
        "for i in range(len(rhymes)):\n",
        "  df = pd.DataFrame({\"x\": rhymes[i], \"idx\": idx[i]})\n",
        "  df_grp = pd.concat([df_grp, df.groupby('idx')['x'].apply(' '.join).reset_index()], ignore_index = True)\n",
        "\n",
        "df_train = df_grp.drop(columns = ['idx'])\n",
        "\n",
        "\n",
        "#structure the dataset: word1 - word2 - label with all the possible combination of words that rhyme\n",
        "\n",
        "#reverse the pairs too double the observations:  w1 - w2  -> w2 - w1\n",
        "coppie, coppie_rev = [], []\n",
        "#create pairs of words that rhymes\n",
        "for parole in df_train['x']:\n",
        "    parole_lista = parole.split()\n",
        "    coppie.extend([(coppia[0], coppia[1]) for coppia in itertools.combinations(parole_lista, 2)])\n",
        "    coppie_rev.extend([(coppia[1], coppia[0]) for coppia in itertools.combinations(parole_lista, 2)])\n",
        "\n",
        "#concat df and reversed df\n",
        "df_train = pd.DataFrame(coppie, columns=['x1', 'x2'])\n",
        "df_rev = pd.DataFrame(coppie_rev, columns=['x1', 'x2'])\n",
        "df_train = pd.concat([df_train, df_rev], ignore_index = True).drop_duplicates(subset = ['x1', 'x2'])\n",
        "df_train['label'] = 0 #0 indicate that 2 words rhyme\n",
        "\n",
        "#create example of words that don't rhymes\n",
        "all_words = list(set(df_train.x1))\n",
        "coppie = []\n",
        "for i in range(len(df_train)*2):\n",
        "    coppie.extend([(random.choice(all_words), random.choice(all_words)) for coppia in itertools.combinations(parole_lista, 2)])\n",
        "\n",
        "df_not_rhymes = pd.DataFrame(coppie, columns=['x1', 'x2'])\n",
        "df_not_rhymes['label'] = 1\n",
        "\n",
        "\n",
        "#concat the dataframes\n",
        "df_train = pd.concat([df_train, df_not_rhymes], ignore_index = True)\n",
        "df_train.sample(5)"
      ],
      "metadata": {
        "id": "gRPQlNQbpMe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_to_features(word, num_features):\n",
        "  '''\n",
        "  create numerical index to indicate the last n (num features) letters\n",
        "  '''\n",
        "  #extract the lasts n letters, if a word is shorter, than apply padding value\n",
        "  padding_value = 0\n",
        "  features = [ord(char) for char in word[-num_features:]] if len(word) >= num_features else [padding_value] * (num_features - len(word)) + [ord(char) for char in word]\n",
        "\n",
        "  return features"
      ],
      "metadata": {
        "id": "3t6qCmIk_XSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract the last letters of each word for the model\n",
        "num_features = 3\n",
        "X1_features = np.array([word_to_features(word, num_features) for word in df_train.x1])\n",
        "X2_features = np.array([word_to_features(word, num_features) for word in df_train.x2])\n",
        "y = df_train.label.values\n",
        "\n",
        "# train val test split\n",
        "X1_train, X1_temp, X2_train, X2_temp, y_train, y_temp = train_test_split(X1_features, X2_features, y, test_size=0.2)\n",
        "X1_val, X1_test, X2_val, X2_test, y_val, y_test = train_test_split(X1_temp, X2_temp, y_temp, test_size=0.5)"
      ],
      "metadata": {
        "id": "33E7srXfBz_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "FGIc-PUpDmMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_x1 = Input(shape=(num_features,))\n",
        "input_x2 = Input(shape=(num_features,))\n",
        "concatenated = concatenate([input_x1, input_x2])\n",
        "\n",
        "dense1 = Dense(256, activation='relu')(concatenated)\n",
        "output = Dense(1, activation='sigmoid')(dense1)\n",
        "model = Model(inputs=[input_x1, input_x2], outputs=output)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "rmjFgUYWCVMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([X1_train, X2_train], y_train, epochs=150, batch_size=64, validation_data=([X1_val, X2_val], y_val), callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "1O_oY2PSDpHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Valutazione del modello sul test set\n",
        "print(\"TESTING\")\n",
        "test_loss, test_accuracy = model.evaluate([X1_test, X2_test], y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v6RRwuVCiIH",
        "outputId": "d67d58fd-cf3c-4b04-c32e-4882a63d8cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TESTING\n",
            "199/199 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.9050\n",
            "Test Accuracy: 0.9050472974777222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/Text Mining/Models/Rhyme_detector', save_format='tf')"
      ],
      "metadata": {
        "id": "yXtTaaSoOxWh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}